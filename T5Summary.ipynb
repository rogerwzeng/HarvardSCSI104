{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvZ6h/juVB1X6MgSPSFS9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerwzeng/e104/blob/main/T5Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research Paper Summarization\n",
        "## I wrote this simple script to help me with weekly assignment of doing research summaries for the E-11 course. It uses a long text summarization based on the T5 model. Thanks to Peter for the original code. I only had to add a wrapper.\n",
        "## Note, this should only assist, not replace, reading the paper. I found the quality of summarization to be one and off, so it is important to *actually read* the paper itself, so no importance points are missed.\n",
        "## Anyhow, here we go."
      ],
      "metadata": {
        "id": "J2Re6dRlYhl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make sure rune-time env libraries are all set up "
      ],
      "metadata": {
        "id": "NELweLrirMjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "!pip install pyPDF2\n",
        "!pip install jedi==0.10\n",
        "!pip install koila"
      ],
      "metadata": {
        "id": "9CXoUB1okCWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter research paper file name (must be PDF) below"
      ],
      "metadata": {
        "id": "37r3C2IBOVFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_file = \"\"  # Name and path (if any) of research paper PDF"
      ],
      "metadata": {
        "id": "DhsL3ATsOg8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in PDF "
      ],
      "metadata": {
        "id": "5xcEmZmxrany"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "with open(in_file, \"rb\") as pdf_file:\n",
        "    reader = PdfReader(pdf_file)\n",
        "    pg = len(reader.pages)\n",
        "    print(f\"Total Pages: {pg}\")\n",
        "    long_text = \"\"\n",
        "    for page in reader.pages:\n",
        "        long_text += page.extract_text() + \"\\n\"\n",
        "# print(text)"
      ],
      "metadata": {
        "id": "zOIrsSCaq_ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long text summarization with long-t5-tglobal-base-16384-book-summary model\n",
        "\n",
        "Link to model card: [pszemraj/long-t5-tglobal-base-16384-book-summary](https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-book-summary)\n",
        "\n",
        "by [Peter](https://github.com/pszemraj)\n"
      ],
      "metadata": {
        "id": "ESBvR09coOWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    \"pszemraj/long-t5-tglobal-base-16384-book-summary\",\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Va1NElGcbHVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deal with long papers with lazy feeding"
      ],
      "metadata": {
        "id": "zlTwrASHOx6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for large input document, you may run out of GPU memory. \n",
        "# Chunk it up into batches by # of pages (16 page just a huerestic)\n",
        "from koila import lazy\n",
        "\n",
        "long_text = lazy(long_text, batch=pg//16)"
      ],
      "metadata": {
        "id": "FlUWGXYD5UnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run model to get summary text.\n",
        "### Adjust \"max_length\" and \"min_length\" to suit your needs"
      ],
      "metadata": {
        "id": "keEG93EZO3oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "params = {\n",
        "    \"max_length\": 512,\n",
        "    \"min_length\": 192,\n",
        "    \"no_repeat_ngram_size\": 3,\n",
        "    \"early_stopping\": True,\n",
        "    \"repetition_penalty\": 4.5,\n",
        "    \"length_penalty\": 0.3,\n",
        "    \"encoder_no_repeat_ngram_size\": 3,\n",
        "    \"num_beams\": 4,\n",
        "} # parameters for text generation out of model\n",
        "\n",
        "result = summarizer(long_text, **params)\n",
        "\n",
        "print(result[0]['summary_text'])"
      ],
      "metadata": {
        "id": "hx8zHh5wBFbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://huggingface.co/pszemraj/long-t5-tglobal-base-16384-book-summary"
      ],
      "metadata": {
        "id": "BY57gXwXPHgA"
      }
    }
  ]
}